Алгоритм умножения матриц на JavaScript:
```javascript
function multiplyMatrix(matrix1, matrix2) {
  var result = [];
  var rows1 = matrix1.length;
  var cols1 = matrix1[0].length;
  var rows2 = matrix2.length;
  var cols2 = matrix2[0].length;
  
  if (cols1 !== rows2) {
    return result;
  }
  
  for (var i = 0; i < rows1; i++) {
    result[i] = [];
    for (var j = 0; j < cols2; j++) {
      result[i][j] = 0;
      for (var k = 0; k < cols1; k++) {
        result[i][j] += matrix1[i][k] * matrix2[k][j];
      }
    }
  }
  
  return result;
}
```
Пример использования:
```javascript
var matrix1 = [[1, 2, 3], [4, 5, 6]];
var matrix2 = [[7, 8], [9, 10], [11, 12]];
var result = multiplyMatrix(matrix1, matrix2);
console.log(result);
```
Алгоритм умножения матриц на чистом C:
```c
#include <stdio.h>
void multiplyMatrix(int matrix1[][3], int matrix2[][2], int result[][2]) {
  int rows1 = sizeof(matrix1) / sizeof(matrix1[0]);
  int cols1 = sizeof(matrix1[0]) / sizeof(matrix1[0][0]);
  int rows2 = sizeof(matrix2) / sizeof(matrix2[0]);
  int cols2 = sizeof(matrix2[0]) / sizeof(matrix2[0][0]);
  
  if (cols1 != rows2) {
    return;
  }
  
  for (int i = 0; i < rows1; i++) {
    for (int j = 0; j < cols2; j++) {
      result[i][j] = 0;
      for (int k = 0; k < cols1; k++) {
        result[i][j] += matrix1[i][k] * matrix2[k][j];
      }
    }
  }
}
int main() {
  int matrix1[2][3] = {{1, 2, 3}, {4, 5, 6}};
  int matrix2[3][2] = {{7, 8}, {9, 10}, {11, 12}};
  int result[2][2];
  
  multiplyMatrix(matrix1, matrix2, result);
  
  for (int i = 0; i < sizeof(result) / sizeof(result[0]); i++) {
    for (int j = 0; j < sizeof(result[0]) / sizeof(result[0][0]); j++) {
      printf("%d ", result[i][j]);
    }
    printf("\n");
  }
  
  return 0;
}
```
Обратите внимание, что в данном примере происходит умножение матриц размером 2x3 и 3x2.